The Media Cloud system manages feeds for media sources, downloads each of those feeds periodically, downloads every url references in a
downloaded feed, and extracts from those downloaded urls the substantive plain text content of each story (minus ads, navigation, and
other cruft). From that extracted text, it generates some tags for each story and also generates a set of word vectors, which is just a
fancy way of saying word counts for each story. The following document describes what word vector data the system generates and points
to the various parts of the code that generate the vectors.

Media Cloud makes available the following sorts of word vector data:

* story_sentences - full sentence text for each sentence for each story

* story_sentence_words - counts of stemmed, tiny-stopworded words for each sentence (points back to story_sentences)

* daily_media_words - sum of story word counts for each word each media source each day

* weekly_media_words - sum of story word counts for each word each media source each week

* total_daily_media_words - sum of story word counts for each media source each day

* top_500_weekly_media_words - top 500 long-stopworded words from weekly_media_words for each media source each week

All of the vectoring code is in MediaWords::StoryVectors.  The relevant MediaWords::StoryVectors functions are:

* update_story_sentence_words_and_language( $db, $stories_id ) - Given a single story, fill in the story vectors for that story
  and identify a language for the whole story and separate sentences.
  This is called from mediawords_extract_and_vector_locally.pl via MediaWords::DBI::Stories::add_vectors() for each story immediately after it is extracted.  This is where the guts of the vectoring system are -- if you want to know the details of the sentence parsing, tokenizing, stemming, etc, look here.  This gets called automatically every time a story is extracted via
  script/mediawords_extract_and_vector_locally.pl.

* update_aggregate_words( $db ) - Update all of the aggregate vector tables for all days up to but not including the current
  day for which no data already exists.  If the day is in the middle of a week, also update the weekly tables for the 
  current, incomplete week.  This should be run once a day to keep the aggregate tables up date, but you can run it
  less frequently and it will do the right thing, filling in the data for any missing days / week.  You can execute
  this from the command line via the script script/mediawords_update_aggregate_vectors.pl .

* fill_story_sentence_words( $db ) - Refill all of the story vectors for all stories pointed to by ssw_queue (and delete each story from
  ssw_queue as it is filled). Only refills 1000 stories at a time, so you have to run this repeatedly to fill all stories (postgres
  procedures have to act as single transaction, so it's important to do this work in chunks to avoid Very Long Running Transactions).
  THERE'S NO NEED TO CALL THIS UNLESS YOU WANT TO REGENERATE ALL VECTORS BECAUSE YOU'VE CHANGED THE VECTORING CODE.  The vectors
  should be getting updated continuously updated during the extraction process.  If you're sure you need to, you can execute this
  from the command line via the script script/mediawords_fill_story_words.pl . 

The stopwording code lives in MediaWords::Util::StopWords.  We currently stopword against a combined English and Russian list, 
against tiny (~150 words for each language), short (~1k), and long (~4k) lists of words.




