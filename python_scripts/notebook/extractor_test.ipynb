{
 "metadata": {
  "name": "",
  "signature": "sha256:e6196607dd61c04b365dcdf3394745636fe47d3eacdb8cc3057303b0c60176d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extractor evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook evaluates both Media Cloud's internal extractors and third party FLOSS extractor libraries across a corpus of hand annotated articles.\n",
      "\n",
      "Readers may wish to skip to the results section at the end."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set up / Methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import os.path\n",
      "\n",
      "api_key = cPickle.load( file( os.path.expanduser( '~/mediacloud_api_key.pickle' ), 'r' ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import os.path\n",
      "\n",
      "cPickle.dump( api_key, file( os.path.expanduser( '~/mediacloud_api_key.pickle' ), 'wb' ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('../../foreign_modules/python/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loc_key = 'f66a50230d54afaf18822808aed649f1d6ca72b08fb06d5efb6247afe9fbae52'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mediacloud, requests, csv, sys, os, json, cPickle\n",
      "\n",
      "def get_download( downloads_id ):\n",
      "    download = requests.get('https://api.mediacloud.org/api/v2/downloads/single/'+str(downloads_id)+'?key='+api_key)\n",
      "    return download.json()[0]\n",
      "\n",
      "def extract_story( preprocessed_lines, title, description, extractor_method ):\n",
      "    extract_params = {'key':loc_key, 'preprocessed_lines':preprocessed_lines, \n",
      "                           'story_title':title, 'story_description':description, 'extractor_method': extractor_method}\n",
      "    \n",
      "    extract_result = requests.put('http://0:3000/api/v2/extractlines/extract',data=json.dumps(extract_params), \n",
      "                                headers = {'Content-type': 'application/json'})\n",
      "    \n",
      "    extract_result.raise_for_status()\n",
      "    return extract_result.json()\n",
      "\n",
      "def get_story_lines( raw_content ):\n",
      "    story_lines_params = {'key':loc_key, 'body_html':raw_content }\n",
      "    headers = {'Content-type': 'application/json'}\n",
      "    story_lines = requests.put('http://0:3000/api/v2/extractlines/story_lines',data=json.dumps(story_lines_params), \n",
      "                               params={ 'key': loc_key },headers=headers)\n",
      "    \n",
      "    story_lines.raise_for_status()\n",
      "    \n",
      "    return story_lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "import tempfile\n",
      "import codecs\n",
      "import time\n",
      "from lxml import html\n",
      "\n",
      "#download = get_download( downloads_id )\n",
      "#raw_content = download[u'raw_content']\n",
      "\n",
      "def extract_with_boilerpipe( raw_content ):\n",
      "    with tempfile.NamedTemporaryFile( suffix='.html', delete=False ) as t:\n",
      "        #print t.name\n",
      "    \n",
      "        UTF8Writer = codecs.getwriter('utf8')\n",
      "        t.file = UTF8Writer(t.file)\n",
      "        t.file.write( raw_content )\n",
      "    \n",
      "        t.close()\n",
      "        #time.sleep( 2 )\n",
      "        #print \"original article tmp file \", t.name\n",
      "        \n",
      "        #input_file = '/tmp/416655019.htm'\n",
      "        input_file = t.name\n",
      "        \n",
      "        output_tmp = tempfile.NamedTemporaryFile( suffix='.html', delete=False )\n",
      "        \n",
      "        output_file = output_tmp.name\n",
      "        #output_file = '/tmp/highlighted.html'\n",
      "        #print output_file\n",
      "        \n",
      "        subprocess.check_output(['java', '-jar',\n",
      "                               '/home/dlarochelle/dev_scratch/boilerpipe_test/out/artifacts/boilerpipe_test_jar/boilerpipe_test.jar',\n",
      "                               input_file, output_file ] )\n",
      "        f = open( output_file, 'rb' )\n",
      "        \n",
      "        annotated_file_str = f.read()\n",
      "        \n",
      "        #t.unlink( t.name )\n",
      "        output_tmp.close()\n",
      "        #output_tmp.unlink( output_tmp.name )\n",
      "\n",
      "    tree = html.fromstring( annotated_file_str )   \n",
      "    spans = tree.xpath('//span[@class=\"x-boilerpipe-mark1\"]')\n",
      "    boiler_pipe_lines = [ etree.tostring(s) for s in spans ]\n",
      "\n",
      "    ret = { 'extracted_html': boiler_pipe_lines }\n",
      "    return ret\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#f = open( '/tmp/tmp01CV6F.html' )\n",
      "#annotated_file_str = f.read()\n",
      "#tree = html.fromstring( annotated_file_str )   \n",
      "#spans = tree.xpath('//span[@class=\"x-boilerpipe-mark1\"]')\n",
      "#span = spans[0]\n",
      "#etree.tostring( span )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import readability\n",
      "\n",
      "def extract_with_python_readability( raw_content ):\n",
      "    doc = readability.Document( raw_content )\n",
      "    \n",
      "    return [ doc.short_title(),\n",
      "             doc.summary() ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import goose\n",
      "\n",
      "def extract_with_python_goose( raw_content ):\n",
      "    g = goose.Goose()\n",
      "    \n",
      "    r = g.extract( raw_html=raw_content )\n",
      "    return [r.title, r.cleaned_text ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import justext\n",
      "\n",
      "def extract_with_justext( raw_content ):\n",
      "    ret = []\n",
      "    \n",
      "    paragraphs = justext.justext( raw_content, justext.get_stoplist('Portuguese') )\n",
      "    \n",
      "    #p = paragraphs[0]\n",
      "    for p in paragraphs:\n",
      "        if not p.is_boilerplate:\n",
      "            ret.append(p.text)\n",
      "            \n",
      "    return ret\n",
      "\n",
      "#extract_with_justext( raw_content )\n",
      "#raw_html\n",
      "\n",
      "#justext.get_stoplists()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "\n",
      "def get_extractor_training_text( downloads_id, preprocessed_lines ):\n",
      "    extractor_training_lines_result = requests.get(\n",
      "                                                   'https://api.mediacloud.org/api/v2/extractlines/extractor_training_lines/' + str(downloads_id),\n",
      "                                               headers = {'Content-type': 'application/json'}\n",
      "                                               , params= {'key': api_key}\n",
      "                                               )\n",
      "\n",
      "    extractor_training_lines_result.raise_for_status()\n",
      "\n",
      "    extractor_training_lines_result = extractor_training_lines_result.json()\n",
      "    \n",
      "    line_numbers = [ x['line_number'] for x in extractor_training_lines_result ]\n",
      "    \n",
      "    line_numbers = sorted(line_numbers)\n",
      "    \n",
      "    line_numbers.sort()\n",
      "    \n",
      "    #print line_numbers\n",
      "    \n",
      "    return operator.itemgetter( * line_numbers )( preprocessed_lines  )\n",
      "\n",
      "import operator\n",
      "\n",
      "def get_extracted_text( extractor_results ):\n",
      "    included_line_numbers = extractor_results['included_line_numbers']\n",
      "    #print included_line_numbers\n",
      "    \n",
      "    dl = extractor_results['download_lines']\n",
      "   \n",
      "    if len( included_line_numbers ) == 0:\n",
      "        return []\n",
      "    else:    \n",
      "        return operator.itemgetter( * extractor_results['included_line_numbers']   )(dl)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Levenshtein\n",
      "\n",
      "def lines_to_comparable_text( lines ):\n",
      "    text = u\"\\n\\n\".join([ clean_for_comparison(line) for line in lines ])\n",
      "    \n",
      "    if text == '':\n",
      "        text = u''\n",
      "        \n",
      "    return text\n",
      "\n",
      "def compare_accuracy( lines, lines_expected ):\n",
      "    return Levenshtein.distance( lines_to_comparable_text( lines ) , lines_to_comparable_text( lines_expected ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_anncestors( element ):\n",
      "    anncestors = [ element ];\n",
      "    anncestor = element.getparent()\n",
      "    \n",
      "    while anncestor != None :\n",
      "        #print 'loop'\n",
      "        anncestors.append( anncestor )\n",
      "        anncestor = anncestor.getparent()\n",
      "        \n",
      "    return anncestors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def text_from_lxml_object( obj):\n",
      "    if type(obj) is etree._ElementStringResult:\n",
      "        return u'' + obj\n",
      "    if type(obj) ==  etree._ElementUnicodeResult:\n",
      "        return u'' + obj \n",
      "    else:\n",
      "        try:\n",
      "            return etree.tostring( obj , method='text', encoding=\"UTF-8\") \n",
      "        except:\n",
      "            print type(obj)\n",
      "            print obj\n",
      "            \n",
      "            raise ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import etree\n",
      "\n",
      "downloads_id =  582817308 \n",
      "download = get_download( downloads_id )\n",
      "raw_content = download[ 'raw_content' ]\n",
      "with open( '/tmp/' + str(downloads_id) , 'wb' ) as f:\n",
      "    f.write( raw_content )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import tokenize\n",
      "\n",
      "def remove_duplicate_sentences( text_lines, story ):\n",
      "    comp_text = lines_to_comparable_text( text_lines )\n",
      "    sentences = [ sent.strip()  for sent in tokenize.sent_tokenize( comp_text ) ]\n",
      "    #print sentences\n",
      "    non_duplicate_sentences = [sentence for sentence in sentences if not sentence_is_duplicate( sentence, story ) ] \n",
      "    return u\"\\n\".join( non_duplicate_sentences )\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def text_children( element):\n",
      "    ret =  [ t for t in element.xpath(\"//text()\" ) if t.getparent() == element ]\n",
      "    assert len( ret ) <= 2\n",
      "    \n",
      "    if len( ret ) == 2:\n",
      "        assert ret[0].is_text\n",
      "        assert ret[1].is_tail\n",
      "    \n",
      "    for r in ret:\n",
      "        if r.is_text:\n",
      "            assert element.text == r\n",
      "        else:\n",
      "            assert r.is_tail\n",
      "            assert element.tail == r\n",
      "            \n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def html_strip( str ):\n",
      "    if str.isspace() or str == '':\n",
      "        return u' '\n",
      "    \n",
      "    if str == '<':\n",
      "        return u' '        \n",
      "    \n",
      "    try:\n",
      "        return html.fromstring(str).text_content()    \n",
      "    except:\n",
      "        print \"Unexpected error on string '\" + str + \"'\" , sys.exc_info()[0]\n",
      "        #raise\n",
      "        return u''       \n",
      "\n",
      "def clean_for_comparison( str ):\n",
      "    if len(str) > 0:\n",
      "        ret = html_strip( str )\n",
      "    else:\n",
      "        return str\n",
      "    \n",
      "    return ret    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_with_mc_extractor( eto, method ):\n",
      "    story = eto['story']\n",
      "    preprocessed_lines = eto['preprocessed_lines']\n",
      "    title = story[u'title']\n",
      "    description = story[u'description']\n",
      "    \n",
      "    extract_result = extract_story( preprocessed_lines, title, description, 'HeuristicExtractor')\n",
      "    html_lines = get_extracted_text( extract_result )\n",
      "    \n",
      "    ret = {}\n",
      "    \n",
      "    ret['extracted_html'] = html_lines\n",
      "    \n",
      "    return ret\n",
      "\n",
      "def extract_with_heur( eto ):\n",
      "    return extract_with_mc_extractor( eto, 'HeuristicExtractor' )\n",
      "\n",
      "def extract_with_crf( eto ):\n",
      "    return extract_with_mc_extractor( eto, 'CrfExtractor' )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import difflib\n",
      "from IPython.display import HTML\n",
      "\n",
      "from collections import Counter\n",
      "\n",
      "def ratcliff_obershelp_compare( actual_text, expected_text ):\n",
      "    \n",
      "    words_expected = actual_text.split()\n",
      "    words_crf      = expected_text.split()\n",
      "    \n",
      "    differ = difflib.Differ( )\n",
      "    \n",
      "    #print words_crf[:10]\n",
      "    #print words_expected[:10]\n",
      "    list( differ.compare( words_crf , words_expected ) )\n",
      "    counts = Counter([ d[0] for d in differ.compare( words_expected, words_crf   ) ])\n",
      "    \n",
      "    tp = counts[' ']\n",
      "    fp = counts['+']\n",
      "    fn = counts['-']\n",
      "    \n",
      "    if float(tp+fp) == 0:\n",
      "        precision = 0.0\n",
      "    else:\n",
      "        precision = tp/float(tp+fp)\n",
      "        \n",
      "    if float( tp + fn ) == 0:\n",
      "        recall = 0\n",
      "    else:\n",
      "        recall    = tp/float( tp + fn )\n",
      "    \n",
      "    if ( precision + recall ) > 0:\n",
      "        f1 = 2*(precision*recall)/( precision + recall )\n",
      "    else:\n",
      "        f1 = 0\n",
      "    \n",
      "    ret = { 'precision': precision,\n",
      "        'recall': recall,\n",
      "        'f1': f1\n",
      "    }\n",
      "    \n",
      "    return ret\n",
      "\n",
      "def compare_with_expected( extractor_name, actual_text, expected_text, story ):\n",
      "    #actual_text = lines_to_comparable_text( actual_lines )\n",
      "    #expected_text = lines_to_comparable_text( expected_lines )\n",
      "    ret = {}\n",
      "    ret[ extractor_name ] = ratcliff_obershelp_compare( actual_text, expected_text )\n",
      "    \n",
      "    #dedup_text = remove_duplicate_sentences( actual_lines, story )\n",
      "    \n",
      "    #ret[ extractor_name + \"_dedup\" ] = ratcliff_obershelp_compare( dedup_text, expected_text )\n",
      "    \n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_extraction_results( eto ):\n",
      "\n",
      "    raw_content = eto[ 'raw_content' ]\n",
      "    \n",
      "    ret = {}\n",
      "    \n",
      "    ret['heur'] = extract_with_heur( eto )\n",
      "    ret['crf'] = extract_with_crf( eto )\n",
      "    ret['boiler_pipe'] =   extract_with_boilerpipe( raw_content)\n",
      "    ret['python_readibilty'] = { 'extracted_html': extract_with_python_readability( raw_content ) }\n",
      "    ret['py_goose']  = { 'extracted_html': extract_with_python_goose( raw_content ) }\n",
      "    ret['justext'] =  { 'extracted_html': extract_with_justext( raw_content ) }\n",
      "    \n",
      "    for method, result in ret.iteritems():\n",
      "        if 'extracted_text' not in result:\n",
      "            result['extracted_text'] = lines_to_comparable_text( result['extracted_html' ] )\n",
      "            \n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compare_extractors_for_download( downloads_id ):\n",
      "    \n",
      "    eto = create_extractor_training_object( downloads_id )\n",
      "    \n",
      "    return comp_extractors( eto )    \n",
      "    \n",
      "def comp_extractors( eto ):    \n",
      "    downloads_id = eto['downloads_id']\n",
      "    media_id     = eto['media_id' ]\n",
      "    story = eto['story']\n",
      "    raw_content = eto['raw_content']\n",
      "    preprocessed_lines = eto['preprocessed_lines']\n",
      "    expected_text = eto['expected_text']\n",
      "        \n",
      "    title = story[u'title']\n",
      "    description = story[u'description']\n",
      "    url = story[u'url']\n",
      "    \n",
      "    extraction_results = get_extraction_results( eto )\n",
      "    \n",
      "    comp_results = {}\n",
      "        \n",
      "    comp_results['downloads_id'] = downloads_id\n",
      "    \n",
      "    comp_results['media_id']  = media_id\n",
      "    \n",
      "    for name, value in extraction_results.iteritems():\n",
      "        #print name, value\n",
      "        comp_results.update (compare_with_expected( name, value['extracted_text'], expected_text, story ) )\n",
      "    \n",
      "    return comp_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_extractor_training_object( downloads_id, expected_text=None ):\n",
      "    download = get_download( downloads_id )\n",
      "    \n",
      "    raw_content = download[u'raw_content']\n",
      "    stories_id = download[u'stories_id']\n",
      "    \n",
      "    #print download['url']\n",
      "    \n",
      "    story = requests.get('https://api.mediacloud.org/api/v2/stories/single/'+str(stories_id)+'?key='+api_key)\n",
      "    \n",
      "    story = story.json()[0]\n",
      "    \n",
      "    story_lines = get_story_lines( raw_content )\n",
      "    #print story_lines.content\n",
      "    preprocessed_lines = story_lines.json()\n",
      "    \n",
      "    if not expected_text:\n",
      "        expected_lines = get_extractor_training_text( downloads_id, preprocessed_lines  )\n",
      "        expected_text  = lines_to_comparable_text( expected_lines )\n",
      "\n",
      "    ret = { 'downloads_id': downloads_id,\n",
      "           'raw_content': raw_content,\n",
      "           'media_id': story['media_id'],\n",
      "           'story': story,\n",
      "           'preprocessed_lines': preprocessed_lines,\n",
      "           'expected_text': expected_text\n",
      "           }\n",
      "    \n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "sys.path.append('../')\n",
      "\n",
      "import mc_config\n",
      "\n",
      "def get_db_info():\n",
      "    config_file = mc_config.read_config()\n",
      "    \n",
      "    db_infos = config_file['database']\n",
      "    db_info = next (db_info for db_info in db_infos if db_info['port'] == '6000' )\n",
      "    return db_info\n",
      "\n",
      "import psycopg2\n",
      "#import solr_reimport\n",
      "import psycopg2.extras\n",
      "\n",
      "db_info = get_db_info()\n",
      "\n",
      "conn = psycopg2.connect( database=db_info['db'], user=db_info['user'], \n",
      "                        password=db_info['pass'], host=db_info['host'], port=db_info['port'] )\n",
      "\n",
      "\n",
      "story_sentence_counts_cache = {}\n",
      "\n",
      "def get_sentence_counts( sentence, story ):\n",
      "\n",
      "    stories_id = story['stories_id']\n",
      "    \n",
      "    if not stories_id in story_sentence_counts_cache:\n",
      "        story_sentence_counts_cache[ stories_id ] = {}\n",
      "        \n",
      "    if sentence in story_sentence_counts_cache[ stories_id ]:\n",
      "        return story_sentence_counts_cache[stories_id ][sentence]\n",
      "        \n",
      "    cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
      "    query = '''               \n",
      "                   SELECT MIN( story_sentence_counts_id) AS story_sentence_counts_id, sentence_count, first_stories_id,\n",
      "                   sentence_md5\n",
      "            FROM story_sentence_counts\n",
      "            WHERE sentence_md5  = md5(%(sentence)s)\n",
      "              AND media_id = %(media_id)s\n",
      "              AND publish_week =  DATE_TRUNC( 'week', %(publish_date)s::date )\n",
      "            GROUP BY story_sentence_counts_id\n",
      "    '''\n",
      "    \n",
      "    #print sentence\n",
      "    #md5_sum = md5.new( sentence ).hexdigest()\n",
      "    \n",
      "    params = { 'sentence': sentence,\n",
      "                            'media_id': story['media_id'], \n",
      "                            'publish_date': story['publish_date']\n",
      "                            } \n",
      "    \n",
      "    #print params\n",
      "    \n",
      "    #print eto[ 'story'] ['stories_id' ]\n",
      "    cursor.execute( query, params )\n",
      "    \n",
      "    fetched = cursor.fetchall()\n",
      "    \n",
      "    if len( fetched ) == 0:\n",
      "        story_sentence_counts_cache[ stories_id ][sentence] = None\n",
      "    else:\n",
      "        story_sentence_counts_cache[ stories_id ][sentence] = dict(fetched[0])\n",
      "        \n",
      "    return story_sentence_counts_cache[stories_id ][sentence]\n",
      "    \n",
      "def sentence_is_duplicate( sentence, story ):\n",
      "    sentence_counts = get_sentence_counts( sentence, story )\n",
      "    \n",
      "    if sentence_counts != None:\n",
      "        if sentence_counts['sentence_count'] > 1:\n",
      "            #print \"duplicate sentence\", sentence\n",
      "            return True\n",
      "        elif sentence_counts['first_stories_id'] == story['stories_id']:\n",
      "            return True\n",
      "            #print \"duplicate sentence (diff first_stories_id) \", sentence\n",
      "            \n",
      "    else:\n",
      "        return False\n",
      "        pass\n",
      "        #print \"sentence not found \", sentence \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_extractor_training_objects_legacy ( downloads_ids ):\n",
      "    print downloads_ids\n",
      "    extractor_training_objects = []\n",
      "    for downloads_id in downloads_ids[:]:\n",
      "        print 'downloads_id:', downloads_id\n",
      "        extractor_training_objects.append( create_extractor_training_object( downloads_id ) )\n",
      "        \n",
      "    return extractor_training_objects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "\n",
      "def get_extractor_training_objects_sqlite( db_file ):\n",
      "    \n",
      "    db = sqlite3.connect( db_file )\n",
      "    db.row_factory = sqlite3.Row\n",
      "    \n",
      "    cursor = db.cursor()\n",
      "    \n",
      "    cursor.execute( \"SELECT * from dlannotations  where selected_texts_json is not null order by downloads_id\" )\n",
      "    \n",
      "    extractor_training_objects = []\n",
      "    \n",
      "    skipped_downloads = 0\n",
      "    for row in list( cursor.fetchall() )[:]:\n",
      "        row =  dict([ (k, row[k]) for k in row.keys() ])\n",
      "        \n",
      "        #print row\n",
      "        \n",
      "        row['annotations'] = json.loads( row['annotations_json'] )\n",
      "        row['raw_content'] = u'' + row['raw_content']\n",
      "        row['selected_texts'] = json.loads( row['selected_texts_json'] )\n",
      "    \n",
      "        annotations = row['annotations']\n",
      "        download = get_download( row['downloads_id'] )\n",
      "    \n",
      "        assert row['selected_texts'] != None\n",
      "        assert row['selected_texts'] > 0\n",
      "        \n",
      "        eto = create_extractor_training_object( row['downloads_id'], expected_text=u\"\\n\".join(row['selected_texts']) )\n",
      "               \n",
      "        if eto['raw_content'] != row['raw_content']:\n",
      "            #TODO figure out why these may differ\n",
      "            pass\n",
      "        \n",
      "            #d = difflib.Differ()\n",
      "            #diff = d.compare(eto['raw_content'].splitlines(1), row['raw_content'].splitlines(1))\n",
      "            #print '\\n'.join(diff)\n",
      "        \n",
      "        extractor_training_objects.append( eto )\n",
      "    \n",
      "    \n",
      "    print \"skipped\", skipped_downloads\n",
      "    print \"processed\", len(extractor_training_objects)\n",
      "    \n",
      "    return extractor_training_objects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "def get_data_frame_from_comparision_objects( comparison_objects ):\n",
      "    \n",
      "    new_comps = []\n",
      "    for comp in comparison_objects:\n",
      "        \n",
      "        new_comp = {}\n",
      "        new_comp = { 'downloads_id': comp['downloads_id'] }\n",
      "        \n",
      "        extractor_types = [ k for k in comp.keys() if k not in { 'downloads_id', 'media_id' }  ]\n",
      "        \n",
      "        for extractor_type in extractor_types:\n",
      "            new_comp.update([ ( k + '_' + extractor_type , v) for k,v in comp[ extractor_type ].iteritems() ])\n",
      "            \n",
      "        new_comps.append( new_comp )\n",
      "        \n",
      "    df = pd.DataFrame( new_comps )\n",
      "    df.set_index('downloads_id', inplace=True )\n",
      "    return df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import boilerpipe.extract\n",
      "\n",
      "def extract_with_py_boilerpipe( raw_content ):\n",
      "    e = boilerpipe.extract.Extractor( extractor='ArticleExtractor', html=raw_content )\n",
      "    html = e.getHTML()\n",
      "\n",
      "    ret = { 'extracted_html': html }\n",
      "    return ret\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_results_by_measurement_type( df ):\n",
      "    df.describe(percentiles=[.5] )\n",
      "    result_types = [ 'precision', 'recall', 'f1' ]\n",
      "    for result_type in result_types:\n",
      "        res_columns = [ col for col in df.columns if col.startswith( result_type ) ]\n",
      "        #df.ix[:,['f1_boiler_pipe',\t'f1_crf',\t'f1_heur', 'f1_python_readibilty']].describe()\n",
      "        print df.ix[:,res_columns].describe( percentiles=[0.02, 0.05,.1,0.5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Flags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regenerate_extractor_training_objects = False\n",
      "regenerate_media_id_media_map         = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Constants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brazil_downloads_ids = [391881020,401370599,412896439,412952145,412977048,413024519,413657081,413835576,414040102, \n",
      "                        414257623,414377428,414480464,414818749,414983458,415185946,415186582,415197547,415424551,\n",
      "                        415978069,416026460,416026587,416047494,416047513,416210404,416263840,416306952,416426245,\n",
      "                        416655019,416730837,416802690,417347290,417347524,417368539,417389613,417477837,417653177,\n",
      "                        418489742,418544762,418574641,418648698,418661859,419404469,419440474,419483895,419873979,\n",
      "                        420430754,420599387,420666122,421520860,421834553,422181106,422280595,422910963,423318170,\n",
      "                        424080271,424369085,424796346,424840366,425206279,426405203,426560018,426632784,426709900,\n",
      "                        428449440,429607289,430363249,430995428,433457459,435624796,435659593,461175103,461175549,\n",
      "                        461176415,461176844,461177487,461178557,461178590,461179203,461179222,461179441,461179762,\n",
      "                        461179818,461179954,461179956,461180307,461181039,461181597,461186137,461186258,461186833,\n",
      "                        461187188,461187261,461187577,461188549,461189069,461190586,461193383]\n",
      "\n",
      "sqlite_db_file = 'extractor_train_dbs/dev_2014-11-06T10_18_57-0500.db'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor_training_objects = []\n",
      "if regenerate_extractor_training_objects:\n",
      "    eto_brazil = get_extractor_training_objects_legacy( brazil_downloads_ids )\n",
      "    eto_sqlite = get_extractor_training_objects_sqlite( sqlite_db_file )\n",
      "    extractor_training_objects.extend( eto_brazil  )\n",
      "    extractor_training_objects.extend( eto_sqlite )\n",
      "    cPickle.dump( extractor_training_objects, open(\"extractor_traning_objects.pickle\", \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor_training_objects = cPickle.load( open( \"extractor_traning_objects.pickle\", \"rb\") )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Look up Media Tags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "from collections import Counter\n",
      "\n",
      "mc = mediacloud.api.MediaCloud(api_key)\n",
      "\n",
      "if regenerate_media_id_media_map:\n",
      "    media_id_media_map = {}\n",
      "    \n",
      "    for media_id in list(media_ids)[:]:\n",
      "        media = mc.media( media_id )\n",
      "        media[ 'media_source_tags_ids' ] = set( [ media_source_tag['tags_id'] \n",
      "                                                 for media_source_tag in media['media_source_tags'] ] )\n",
      "        media_id_media_map[ media_id ] = media\n",
      "    \n",
      "    cPickle.dump( media_id_media_map, open(\"media_id_media_map.pickle\", \"wb\"))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "media_id_media_map = cPickle.load( open( \"media_id_media_map.pickle\", \"rb\") )    \n",
      "\n",
      "media_tag_counts = Counter(list ( itertools.chain.from_iterable( media_source['media_source_tags_ids'] for media_source in media_id_media_map.values() )) ) \n",
      "tags_id_to_media_tags_map = {}\n",
      "for media_tag in media_id_media_map.values():\n",
      "    source_tags = media_tag[ 'media_source_tags' ]\n",
      "    for source_tag in source_tags:\n",
      "        tags_id_to_media_tags_map[ source_tag[ 'tags_id' ] ] = source_tag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ (tags_id_to_media_tags_map[tag_id], count) for tag_id, count in media_tag_counts.most_common( 15 ) ]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'egypt_composite_dalia_20140425',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 8878255},\n",
        "  48),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'brazil_20131009',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 8877968},\n",
        "  46),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'news',\n",
        "   u'tag_set': u'egypt_media_type',\n",
        "   u'tag_sets_id': 986,\n",
        "   u'tags_id': 8878259},\n",
        "  43),\n",
        " ({u'description': u'List of sites related to U.S. politics, created for Yochai Benkler and Aaron Shaw\\'s paper \"A Tale of Two Blogospheres: Discursive Practices on the Left and Right\", published in 2010.\\r\\n',\n",
        "   u'label': u'U.S. Campaigns and Elections 2008',\n",
        "   u'show_on_media': 1,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'campaignsandelections_political_2008',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 125},\n",
        "  42),\n",
        " ({u'description': u'Large list of regional TC and newspapers sites, collected by Pew in 2010.',\n",
        "   u'label': u'U.S. Regional Mainstream Media',\n",
        "   u'show_on_media': 1,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'pew_knight_study',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 2453107},\n",
        "  40),\n",
        " ({u'description': u'A site that is a mainstream media outlet, such as The New York Times and The Washington Post; an online-only news outlet, such as Slate, Salon, or the Huffington Post; or a citizen journalism or non-profit news outlet, such as Global Voices or ProPublica',\n",
        "   u'label': u'General News',\n",
        "   u'show_on_media': 1,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'General Online News Media',\n",
        "   u'tag_set': u'media_type',\n",
        "   u'tag_sets_id': 1099,\n",
        "   u'tags_id': 8878416},\n",
        "  37),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'media outlet',\n",
        "   u'tag_set': u'portuguese_media_type',\n",
        "   u'tag_sets_id': 783,\n",
        "   u'tags_id': 8877969},\n",
        "  37),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'largemetroarea',\n",
        "   u'tag_set': u'pkgeog-type',\n",
        "   u'tag_sets_id': 16,\n",
        "   u'tags_id': 2496423},\n",
        "  31),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'alternative',\n",
        "   u'tag_set': u'egypt_valence',\n",
        "   u'tag_sets_id': 987,\n",
        "   u'tags_id': 8878263},\n",
        "  22),\n",
        " ({u'description': u\"Top U.S. mainstream media according Google Ad Planner's measure of unique monthly users.\",\n",
        "   u'label': u'U.S. Mainstream Media',\n",
        "   u'show_on_media': 1,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'ap_english_us_top25_20100110',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 8875027},\n",
        "  20),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'spidered',\n",
        "   u'tag_set': u'spidered',\n",
        "   u'tag_sets_id': 183,\n",
        "   u'tags_id': 8875452},\n",
        "  20),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'dallas_ftworth',\n",
        "   u'tag_set': u'pklocation',\n",
        "   u'tag_sets_id': 15,\n",
        "   u'tags_id': 2497397},\n",
        "  17),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'general_news',\n",
        "   u'tag_set': u'emm_subject',\n",
        "   u'tag_sets_id': 555,\n",
        "   u'tags_id': 8876476},\n",
        "  16),\n",
        " ({u'description': u'List of sites generated by clustering and manually sites discussion the 2012 U.S. presidential election.  This set includes only sources coded as clearly liberal.',\n",
        "   u'label': u'U.S. Partisan Sources 2012 - Liberal',\n",
        "   u'show_on_media': 1,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'partisan_2012_liberal',\n",
        "   u'tag_set': u'collection',\n",
        "   u'tag_sets_id': 5,\n",
        "   u'tags_id': 8878293},\n",
        "  16),\n",
        " ({u'description': None,\n",
        "   u'label': None,\n",
        "   u'show_on_media': 0,\n",
        "   u'show_on_stories': None,\n",
        "   u'tag': u'regional and local media',\n",
        "   u'tag_set': u'portuguese_topic',\n",
        "   u'tag_sets_id': 784,\n",
        "   u'tags_id': 8877973},\n",
        "  16)]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Run extractors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import boilerpipe.extract\n",
      "\n",
      "e = boilerpipe.extract.Extractor( extractor='ArticleExtractor', html=raw_content )\n",
      "print e.getHTML()\n",
      "e."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<HTML lang=\"pt-BR\" prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#\">\n",
        "<style type=\"text/css\">\n",
        "A:before { content:' '; } \n",
        "A:after { content:' '; } \n",
        "SPAN:before { content:' '; } \n",
        "SPAN:after { content:' '; } \n",
        "</style>\n",
        "<BODY class=\"single single-post postid-416828 single-format-standard singular\"><DIV id=\"container\" class=\"container\" role=\"document\"><DIV id=\"content\" class=\"row\"><DIV id=\"main\" class=\"eight columns\" role=\"main\"><DIV class=\"post-box\"><ARTICLE class=\"postagem\" id=\"post-416828\" class=\"post-416828 post type-post status-publish format-standard hentry category-brasil\"><P class=\"dataPostagem\">22 <SPAN class=\"lower\">de</SPAN> dezembro <SPAN class=\"lower\">de</SPAN> 2013, 07:51</P><HEADER class=\"entry-header\"><H1 class=\"entry-title\"><SPAN class=\"branco raio espacamento bg brasil\">BRASIL</SPAN> Pol\u00edcia frustra manifesta\u00e7\u00e3o em shopping na zona sul de S\u00e3o Paulo</H1></HEADER><DIV class=\"entry-content\"><P>A presen\u00e7a da Pol\u00edcia Militar (PM) frustrou uma manifesta\u00e7\u00e3o marcada para acontecer na tarde de hoje (21) no Shopping Campo Limpo, zona sul paulistana. Os chamados \u201crolezinhos\u201d v\u00eam acontecendo em shoppings da cidade como protesto contra o projeto de lei aprovado pela C\u00e2mara Municipal no in\u00edcio do m\u00eas que proibiu a realiza\u00e7\u00e3o de bailes funk. O projeto ainda precisa ser sancionado pelo prefeito Fernando Haddad. Os jovens, ent\u00e3o, marcam encontros onde dezenas de pessoas v\u00e3o aos centros comerciais. Em alguns, casos houve tumulto e deten\u00e7\u00f5es. Hoje, pelo menos oito homens da For\u00e7a T\u00e1tica entraram com armas de balas de borracha e granadas de g\u00e1s no shopping, que estava cheio com o movimento para o Natal. Os policiais chegaram a abordar grupos de jovens dentro do centro comercial, que acabaram deixando o local. Na p\u00e1gina que chamava para o encontro no Facebook, alguns jovens atribu\u00edram \u00e0 presen\u00e7a da PM o fracasso da manifesta\u00e7\u00e3o. A pol\u00edcia tamb\u00e9m estava com homens, viaturas e motos nas entradas e no estacionamento do shopping. Leia mais na <A href=\"http://agenciabrasil.ebc.com.br/noticia/2013-12-21/policia-frustra-manifestacao-em-shopping-na-zona-sul-de-sao-paulo\" target=\"_blank\">Ag\u00eancia Brasil</A>.</P><P class=\"assinatura_exclusiva\"><SPAN>Daniel Mello, Ag\u00eancia Brasil</SPAN></P></DIV></ARTICLE></DIV></DIV></DIV></DIV></BODY></HTML>\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "u'22 de dezembro de 2013, 07:51\\nBRASIL Pol\\xedcia frustra manifesta\\xe7\\xe3o em shopping na zona sul de S\\xe3o Paulo\\nA presen\\xe7a da Pol\\xedcia Militar (PM) frustrou uma manifesta\\xe7\\xe3o marcada para acontecer na tarde de hoje (21) no Shopping Campo Limpo, zona sul paulistana. Os chamados \\u201crolezinhos\\u201d v\\xeam acontecendo em shoppings da cidade como protesto contra o projeto de lei aprovado pela C\\xe2mara Municipal no in\\xedcio do m\\xeas que proibiu a realiza\\xe7\\xe3o de bailes funk. O projeto ainda precisa ser sancionado pelo prefeito Fernando Haddad. Os jovens, ent\\xe3o, marcam encontros onde dezenas de pessoas v\\xe3o aos centros comerciais. Em alguns, casos houve tumulto e deten\\xe7\\xf5es. Hoje, pelo menos oito homens da For\\xe7a T\\xe1tica entraram com armas de balas de borracha e granadas de g\\xe1s no shopping, que estava cheio com o movimento para o Natal. Os policiais chegaram a abordar grupos de jovens dentro do centro comercial, que acabaram deixando o local. Na p\\xe1gina que chamava para o encontro no Facebook, alguns jovens atribu\\xedram \\xe0 presen\\xe7a da PM o fracasso da manifesta\\xe7\\xe3o. A pol\\xedcia tamb\\xe9m estava com homens, viaturas e motos nas entradas e no estacionamento do shopping. Leia mais na Ag\\xeancia Brasil .\\nDaniel Mello, Ag\\xeancia Brasil\\n'"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_content = eto['raw_content']\n",
      "with tempfile.NamedTemporaryFile( suffix='.html', delete=False ) as t:\n",
      "    #print t.name\n",
      "\n",
      "    UTF8Writer = codecs.getwriter('utf8')\n",
      "    t.file = UTF8Writer(t.file)\n",
      "    t.file.write( raw_content )\n",
      "\n",
      "    t.close()\n",
      "    #time.sleep( 2 )\n",
      "    #print \"original article tmp file \", t.name\n",
      "    \n",
      "    #input_file = '/tmp/416655019.htm'\n",
      "    input_file = t.name\n",
      "\n",
      "input_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "'/tmp/tmp7YFxQ7.html'"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#eto = extractor_training_objects[ 0 ]\n",
      "#eto.keys()\n",
      "#print eto['expected_text']\n",
      "#get_extraction_results( eto )\n",
      "#comp_extractors ( eto )\n",
      "\n",
      "extraction_results = []\n",
      "\n",
      "for eto in  extractor_training_objects[:2]:\n",
      "    er = dict( eto )\n",
      "    er[ 'extractor_results'] = get_extraction_results( eto )\n",
      "    \n",
      "    extraction_results.append( er )\n",
      "\n",
      "eto.keys()    \n",
      "#er.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "['story',\n",
        " 'preprocessed_lines',\n",
        " 'media_id',\n",
        " 'downloads_id',\n",
        " 'raw_content',\n",
        " 'expected_text']"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "comps_downloads = []\n",
      "processed = 0\n",
      "skipped = 0\n",
      "for extractor_training_object in extractor_training_objects[:10]:\n",
      "    print 'processed ', processed\n",
      "    print 'skipped ', skipped\n",
      "    print extractor_training_object[ 'downloads_id']\n",
      "    try:\n",
      "        res = comp_extractors( extractor_training_object )\n",
      "        #print res\n",
      "        comps_downloads.append( res )\n",
      "        processed += 1\n",
      "    except Exception, e:\n",
      "        print \"error on download{}\".format( extractor_training_object[ 'downloads_id'] )\n",
      "        e = sys.exc_info()\n",
      "        \n",
      "        import traceback\n",
      "        \n",
      "        traceback.print_exc()\n",
      "        print e\n",
      "        raise e\n",
      "        skipped += 1\n",
      "\n",
      "e\n",
      "#extractor_training_objects\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processed  0\n",
        "skipped  0\n",
        "391881020\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "skipped  0\n",
        "401370599\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "skipped  0\n",
        "412896439\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "skipped  0\n",
        "412952145\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "skipped  0\n",
        "412977048\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "skipped  0\n",
        "413024519\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "skipped  0\n",
        "413657081\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "skipped  0\n",
        "413835576\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "skipped  0\n",
        "414040102\n",
        "processed "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "skipped  0\n",
        "414257623\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "2.718281828459045"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_by_media_tags_id( comps_downloads, media_tags_ids ):\n",
      "    media_ids_matching = set()\n",
      "    #print media_id_media_map\n",
      "    for media_id, media in media_id_media_map.iteritems():\n",
      "        if not media[ 'media_source_tags_ids'].isdisjoint( media_tags_ids ):\n",
      "            media_ids_matching.add( media_id )\n",
      "            \n",
      "    return  [cd for cd in comps_downloads if cd['media_id'] in media_ids_matching ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Results Overall"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = get_data_frame_from_comparision_objects( comps_downloads )\n",
      "print_results_by_measurement_type( df )\n",
      "#df.describe()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       precision_boiler_pipe  precision_crf  precision_heur  \\\n",
        "count              10.000000      10.000000       10.000000   \n",
        "mean                0.772222       0.928525        0.928525   \n",
        "std                 0.308766       0.041151        0.041151   \n",
        "min                 0.063037       0.872690        0.872690   \n",
        "2%                  0.118593       0.872985        0.872985   \n",
        "5%                  0.201927       0.873429        0.873429   \n",
        "10%                 0.340817       0.874167        0.874167   \n",
        "50%                 0.850219       0.933424        0.933424   \n",
        "max                 0.991786       0.982808        0.982808   \n",
        "\n",
        "       precision_justext  precision_py_goose  precision_python_readibilty  \n",
        "count          10.000000           10.000000                    10.000000  \n",
        "mean            0.907790            0.628317                     0.967279  \n",
        "std             0.080010            0.362118                     0.040878  \n",
        "min             0.752212            0.054441                     0.880531  \n",
        "2%              0.757456            0.061005                     0.887990  \n",
        "5%              0.765320            0.070852                     0.899179  \n",
        "10%             0.778428            0.087262                     0.917827  \n",
        "50%             0.924485            0.742309                     0.980334  \n",
        "max             1.000000            0.978261                     1.000000  \n",
        "       recall_boiler_pipe  recall_crf  recall_heur  recall_justext  \\\n",
        "count           10.000000   10.000000    10.000000       10.000000   \n",
        "mean             0.738833    0.710740     0.710740        0.790438   \n",
        "std              0.287460    0.257586     0.257586        0.338369   \n",
        "min              0.017350    0.181963     0.181963        0.141499   \n",
        "2%               0.124742    0.218826     0.218826        0.148330   \n",
        "5%               0.285829    0.274121     0.274121        0.158575   \n",
        "10%              0.554309    0.366280     0.366280        0.175650   \n",
        "50%              0.810234    0.743933     0.743933        0.943260   \n",
        "max              0.979695    1.000000     1.000000        1.000000   \n",
        "\n",
        "       recall_py_goose  recall_python_readibilty  \n",
        "count        10.000000                 10.000000  \n",
        "mean          0.982540                  0.966188  \n",
        "std           0.037184                  0.037156  \n",
        "min           0.901538                  0.892601  \n",
        "2%            0.905556                  0.899876  \n",
        "5%            0.911582                  0.910787  \n",
        "10%           0.921626                  0.928973  \n",
        "50%           1.000000                  0.976836  \n",
        "max           1.000000                  1.000000  \n",
        "       f1_boiler_pipe     f1_crf    f1_heur  f1_justext  f1_py_goose  \\\n",
        "count       10.000000  10.000000  10.000000   10.000000    10.000000   \n",
        "mean         0.744946   0.774217   0.774217    0.798396     0.696688   \n",
        "std          0.296271   0.203908   0.203908    0.281382     0.332937   \n",
        "min          0.027211   0.307073   0.307073    0.239607     0.103261   \n",
        "2%           0.110476   0.351202   0.351202    0.250586     0.114674   \n",
        "5%           0.235374   0.417397   0.417397    0.267056     0.131793   \n",
        "10%          0.443537   0.527722   0.527722    0.294505     0.160326   \n",
        "50%          0.821974   0.811091   0.811091    0.929179     0.825273   \n",
        "max          0.984694   0.973913   0.973913    0.973913     0.989011   \n",
        "\n",
        "       f1_python_readibilty  \n",
        "count             10.000000  \n",
        "mean               0.965652  \n",
        "std                0.020444  \n",
        "min                0.934272  \n",
        "2%                 0.935515  \n",
        "5%                 0.937379  \n",
        "10%                0.940486  \n",
        "50%                0.968270  \n",
        "max                0.988806  \n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>f1_boiler_pipe</th>\n",
        "      <th>f1_crf</th>\n",
        "      <th>f1_heur</th>\n",
        "      <th>f1_justext</th>\n",
        "      <th>f1_py_goose</th>\n",
        "      <th>f1_python_readibilty</th>\n",
        "      <th>precision_boiler_pipe</th>\n",
        "      <th>precision_crf</th>\n",
        "      <th>precision_heur</th>\n",
        "      <th>precision_justext</th>\n",
        "      <th>precision_py_goose</th>\n",
        "      <th>precision_python_readibilty</th>\n",
        "      <th>recall_boiler_pipe</th>\n",
        "      <th>recall_crf</th>\n",
        "      <th>recall_heur</th>\n",
        "      <th>recall_justext</th>\n",
        "      <th>recall_py_goose</th>\n",
        "      <th>recall_python_readibilty</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  0.744946</td>\n",
        "      <td>  0.774217</td>\n",
        "      <td>  0.774217</td>\n",
        "      <td>  0.798396</td>\n",
        "      <td>  0.696688</td>\n",
        "      <td>  0.965652</td>\n",
        "      <td>  0.772222</td>\n",
        "      <td>  0.928525</td>\n",
        "      <td>  0.928525</td>\n",
        "      <td>  0.907790</td>\n",
        "      <td>  0.628317</td>\n",
        "      <td>  0.967279</td>\n",
        "      <td>  0.738833</td>\n",
        "      <td>  0.710740</td>\n",
        "      <td>  0.710740</td>\n",
        "      <td>  0.790438</td>\n",
        "      <td>  0.982540</td>\n",
        "      <td>  0.966188</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  0.296271</td>\n",
        "      <td>  0.203908</td>\n",
        "      <td>  0.203908</td>\n",
        "      <td>  0.281382</td>\n",
        "      <td>  0.332937</td>\n",
        "      <td>  0.020444</td>\n",
        "      <td>  0.308766</td>\n",
        "      <td>  0.041151</td>\n",
        "      <td>  0.041151</td>\n",
        "      <td>  0.080010</td>\n",
        "      <td>  0.362118</td>\n",
        "      <td>  0.040878</td>\n",
        "      <td>  0.287460</td>\n",
        "      <td>  0.257586</td>\n",
        "      <td>  0.257586</td>\n",
        "      <td>  0.338369</td>\n",
        "      <td>  0.037184</td>\n",
        "      <td>  0.037156</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>  0.027211</td>\n",
        "      <td>  0.307073</td>\n",
        "      <td>  0.307073</td>\n",
        "      <td>  0.239607</td>\n",
        "      <td>  0.103261</td>\n",
        "      <td>  0.934272</td>\n",
        "      <td>  0.063037</td>\n",
        "      <td>  0.872690</td>\n",
        "      <td>  0.872690</td>\n",
        "      <td>  0.752212</td>\n",
        "      <td>  0.054441</td>\n",
        "      <td>  0.880531</td>\n",
        "      <td>  0.017350</td>\n",
        "      <td>  0.181963</td>\n",
        "      <td>  0.181963</td>\n",
        "      <td>  0.141499</td>\n",
        "      <td>  0.901538</td>\n",
        "      <td>  0.892601</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  0.715272</td>\n",
        "      <td>  0.768789</td>\n",
        "      <td>  0.768789</td>\n",
        "      <td>  0.863666</td>\n",
        "      <td>  0.550700</td>\n",
        "      <td>  0.947291</td>\n",
        "      <td>  0.827057</td>\n",
        "      <td>  0.893519</td>\n",
        "      <td>  0.893519</td>\n",
        "      <td>  0.909608</td>\n",
        "      <td>  0.383760</td>\n",
        "      <td>  0.946793</td>\n",
        "      <td>  0.653062</td>\n",
        "      <td>  0.664961</td>\n",
        "      <td>  0.664961</td>\n",
        "      <td>  0.823164</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.943692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  0.821974</td>\n",
        "      <td>  0.811091</td>\n",
        "      <td>  0.811091</td>\n",
        "      <td>  0.929179</td>\n",
        "      <td>  0.825273</td>\n",
        "      <td>  0.968270</td>\n",
        "      <td>  0.850219</td>\n",
        "      <td>  0.933424</td>\n",
        "      <td>  0.933424</td>\n",
        "      <td>  0.924485</td>\n",
        "      <td>  0.742309</td>\n",
        "      <td>  0.980334</td>\n",
        "      <td>  0.810234</td>\n",
        "      <td>  0.743933</td>\n",
        "      <td>  0.743933</td>\n",
        "      <td>  0.943260</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.976836</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>  0.956902</td>\n",
        "      <td>  0.891538</td>\n",
        "      <td>  0.891538</td>\n",
        "      <td>  0.951404</td>\n",
        "      <td>  0.959784</td>\n",
        "      <td>  0.984108</td>\n",
        "      <td>  0.975221</td>\n",
        "      <td>  0.961201</td>\n",
        "      <td>  0.961201</td>\n",
        "      <td>  0.949044</td>\n",
        "      <td>  0.939835</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.939452</td>\n",
        "      <td>  0.857325</td>\n",
        "      <td>  0.857325</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.998750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>  0.984694</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.989011</td>\n",
        "      <td>  0.988806</td>\n",
        "      <td>  0.991786</td>\n",
        "      <td>  0.982808</td>\n",
        "      <td>  0.982808</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.978261</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.979695</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "       f1_boiler_pipe     f1_crf    f1_heur  f1_justext  f1_py_goose  \\\n",
        "count       10.000000  10.000000  10.000000   10.000000    10.000000   \n",
        "mean         0.744946   0.774217   0.774217    0.798396     0.696688   \n",
        "std          0.296271   0.203908   0.203908    0.281382     0.332937   \n",
        "min          0.027211   0.307073   0.307073    0.239607     0.103261   \n",
        "25%          0.715272   0.768789   0.768789    0.863666     0.550700   \n",
        "50%          0.821974   0.811091   0.811091    0.929179     0.825273   \n",
        "75%          0.956902   0.891538   0.891538    0.951404     0.959784   \n",
        "max          0.984694   0.973913   0.973913    0.973913     0.989011   \n",
        "\n",
        "       f1_python_readibilty  precision_boiler_pipe  precision_crf  \\\n",
        "count             10.000000              10.000000      10.000000   \n",
        "mean               0.965652               0.772222       0.928525   \n",
        "std                0.020444               0.308766       0.041151   \n",
        "min                0.934272               0.063037       0.872690   \n",
        "25%                0.947291               0.827057       0.893519   \n",
        "50%                0.968270               0.850219       0.933424   \n",
        "75%                0.984108               0.975221       0.961201   \n",
        "max                0.988806               0.991786       0.982808   \n",
        "\n",
        "       precision_heur  precision_justext  precision_py_goose  \\\n",
        "count       10.000000          10.000000           10.000000   \n",
        "mean         0.928525           0.907790            0.628317   \n",
        "std          0.041151           0.080010            0.362118   \n",
        "min          0.872690           0.752212            0.054441   \n",
        "25%          0.893519           0.909608            0.383760   \n",
        "50%          0.933424           0.924485            0.742309   \n",
        "75%          0.961201           0.949044            0.939835   \n",
        "max          0.982808           1.000000            0.978261   \n",
        "\n",
        "       precision_python_readibilty  recall_boiler_pipe  recall_crf  \\\n",
        "count                    10.000000           10.000000   10.000000   \n",
        "mean                      0.967279            0.738833    0.710740   \n",
        "std                       0.040878            0.287460    0.257586   \n",
        "min                       0.880531            0.017350    0.181963   \n",
        "25%                       0.946793            0.653062    0.664961   \n",
        "50%                       0.980334            0.810234    0.743933   \n",
        "75%                       1.000000            0.939452    0.857325   \n",
        "max                       1.000000            0.979695    1.000000   \n",
        "\n",
        "       recall_heur  recall_justext  recall_py_goose  recall_python_readibilty  \n",
        "count    10.000000       10.000000        10.000000                 10.000000  \n",
        "mean      0.710740        0.790438         0.982540                  0.966188  \n",
        "std       0.257586        0.338369         0.037184                  0.037156  \n",
        "min       0.181963        0.141499         0.901538                  0.892601  \n",
        "25%       0.664961        0.823164         1.000000                  0.943692  \n",
        "50%       0.743933        0.943260         1.000000                  0.976836  \n",
        "75%       0.857325        1.000000         1.000000                  0.998750  \n",
        "max       1.000000        1.000000         1.000000                  1.000000  "
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>f1_boiler_pipe</th>\n",
        "      <th>f1_crf</th>\n",
        "      <th>f1_heur</th>\n",
        "      <th>f1_justext</th>\n",
        "      <th>f1_py_goose</th>\n",
        "      <th>f1_python_readibilty</th>\n",
        "      <th>precision_boiler_pipe</th>\n",
        "      <th>precision_crf</th>\n",
        "      <th>precision_heur</th>\n",
        "      <th>precision_justext</th>\n",
        "      <th>precision_py_goose</th>\n",
        "      <th>precision_python_readibilty</th>\n",
        "      <th>recall_boiler_pipe</th>\n",
        "      <th>recall_crf</th>\n",
        "      <th>recall_heur</th>\n",
        "      <th>recall_justext</th>\n",
        "      <th>recall_py_goose</th>\n",
        "      <th>recall_python_readibilty</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  0.744946</td>\n",
        "      <td>  0.774217</td>\n",
        "      <td>  0.774217</td>\n",
        "      <td>  0.798396</td>\n",
        "      <td>  0.696688</td>\n",
        "      <td>  0.965652</td>\n",
        "      <td>  0.772222</td>\n",
        "      <td>  0.928525</td>\n",
        "      <td>  0.928525</td>\n",
        "      <td>  0.907790</td>\n",
        "      <td>  0.628317</td>\n",
        "      <td>  0.967279</td>\n",
        "      <td>  0.738833</td>\n",
        "      <td>  0.710740</td>\n",
        "      <td>  0.710740</td>\n",
        "      <td>  0.790438</td>\n",
        "      <td>  0.982540</td>\n",
        "      <td>  0.966188</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  0.296271</td>\n",
        "      <td>  0.203908</td>\n",
        "      <td>  0.203908</td>\n",
        "      <td>  0.281382</td>\n",
        "      <td>  0.332937</td>\n",
        "      <td>  0.020444</td>\n",
        "      <td>  0.308766</td>\n",
        "      <td>  0.041151</td>\n",
        "      <td>  0.041151</td>\n",
        "      <td>  0.080010</td>\n",
        "      <td>  0.362118</td>\n",
        "      <td>  0.040878</td>\n",
        "      <td>  0.287460</td>\n",
        "      <td>  0.257586</td>\n",
        "      <td>  0.257586</td>\n",
        "      <td>  0.338369</td>\n",
        "      <td>  0.037184</td>\n",
        "      <td>  0.037156</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>  0.027211</td>\n",
        "      <td>  0.307073</td>\n",
        "      <td>  0.307073</td>\n",
        "      <td>  0.239607</td>\n",
        "      <td>  0.103261</td>\n",
        "      <td>  0.934272</td>\n",
        "      <td>  0.063037</td>\n",
        "      <td>  0.872690</td>\n",
        "      <td>  0.872690</td>\n",
        "      <td>  0.752212</td>\n",
        "      <td>  0.054441</td>\n",
        "      <td>  0.880531</td>\n",
        "      <td>  0.017350</td>\n",
        "      <td>  0.181963</td>\n",
        "      <td>  0.181963</td>\n",
        "      <td>  0.141499</td>\n",
        "      <td>  0.901538</td>\n",
        "      <td>  0.892601</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  0.715272</td>\n",
        "      <td>  0.768789</td>\n",
        "      <td>  0.768789</td>\n",
        "      <td>  0.863666</td>\n",
        "      <td>  0.550700</td>\n",
        "      <td>  0.947291</td>\n",
        "      <td>  0.827057</td>\n",
        "      <td>  0.893519</td>\n",
        "      <td>  0.893519</td>\n",
        "      <td>  0.909608</td>\n",
        "      <td>  0.383760</td>\n",
        "      <td>  0.946793</td>\n",
        "      <td>  0.653062</td>\n",
        "      <td>  0.664961</td>\n",
        "      <td>  0.664961</td>\n",
        "      <td>  0.823164</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.943692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  0.821974</td>\n",
        "      <td>  0.811091</td>\n",
        "      <td>  0.811091</td>\n",
        "      <td>  0.929179</td>\n",
        "      <td>  0.825273</td>\n",
        "      <td>  0.968270</td>\n",
        "      <td>  0.850219</td>\n",
        "      <td>  0.933424</td>\n",
        "      <td>  0.933424</td>\n",
        "      <td>  0.924485</td>\n",
        "      <td>  0.742309</td>\n",
        "      <td>  0.980334</td>\n",
        "      <td>  0.810234</td>\n",
        "      <td>  0.743933</td>\n",
        "      <td>  0.743933</td>\n",
        "      <td>  0.943260</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.976836</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>  0.956902</td>\n",
        "      <td>  0.891538</td>\n",
        "      <td>  0.891538</td>\n",
        "      <td>  0.951404</td>\n",
        "      <td>  0.959784</td>\n",
        "      <td>  0.984108</td>\n",
        "      <td>  0.975221</td>\n",
        "      <td>  0.961201</td>\n",
        "      <td>  0.961201</td>\n",
        "      <td>  0.949044</td>\n",
        "      <td>  0.939835</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.939452</td>\n",
        "      <td>  0.857325</td>\n",
        "      <td>  0.857325</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.998750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>  0.984694</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.973913</td>\n",
        "      <td>  0.989011</td>\n",
        "      <td>  0.988806</td>\n",
        "      <td>  0.991786</td>\n",
        "      <td>  0.982808</td>\n",
        "      <td>  0.982808</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.978261</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  0.979695</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "       f1_boiler_pipe     f1_crf    f1_heur  f1_justext  f1_py_goose  \\\n",
        "count       10.000000  10.000000  10.000000   10.000000    10.000000   \n",
        "mean         0.744946   0.774217   0.774217    0.798396     0.696688   \n",
        "std          0.296271   0.203908   0.203908    0.281382     0.332937   \n",
        "min          0.027211   0.307073   0.307073    0.239607     0.103261   \n",
        "25%          0.715272   0.768789   0.768789    0.863666     0.550700   \n",
        "50%          0.821974   0.811091   0.811091    0.929179     0.825273   \n",
        "75%          0.956902   0.891538   0.891538    0.951404     0.959784   \n",
        "max          0.984694   0.973913   0.973913    0.973913     0.989011   \n",
        "\n",
        "       f1_python_readibilty  precision_boiler_pipe  precision_crf  \\\n",
        "count             10.000000              10.000000      10.000000   \n",
        "mean               0.965652               0.772222       0.928525   \n",
        "std                0.020444               0.308766       0.041151   \n",
        "min                0.934272               0.063037       0.872690   \n",
        "25%                0.947291               0.827057       0.893519   \n",
        "50%                0.968270               0.850219       0.933424   \n",
        "75%                0.984108               0.975221       0.961201   \n",
        "max                0.988806               0.991786       0.982808   \n",
        "\n",
        "       precision_heur  precision_justext  precision_py_goose  \\\n",
        "count       10.000000          10.000000           10.000000   \n",
        "mean         0.928525           0.907790            0.628317   \n",
        "std          0.041151           0.080010            0.362118   \n",
        "min          0.872690           0.752212            0.054441   \n",
        "25%          0.893519           0.909608            0.383760   \n",
        "50%          0.933424           0.924485            0.742309   \n",
        "75%          0.961201           0.949044            0.939835   \n",
        "max          0.982808           1.000000            0.978261   \n",
        "\n",
        "       precision_python_readibilty  recall_boiler_pipe  recall_crf  \\\n",
        "count                    10.000000           10.000000   10.000000   \n",
        "mean                      0.967279            0.738833    0.710740   \n",
        "std                       0.040878            0.287460    0.257586   \n",
        "min                       0.880531            0.017350    0.181963   \n",
        "25%                       0.946793            0.653062    0.664961   \n",
        "50%                       0.980334            0.810234    0.743933   \n",
        "75%                       1.000000            0.939452    0.857325   \n",
        "max                       1.000000            0.979695    1.000000   \n",
        "\n",
        "       recall_heur  recall_justext  recall_py_goose  recall_python_readibilty  \n",
        "count    10.000000       10.000000        10.000000                 10.000000  \n",
        "mean      0.710740        0.790438         0.982540                  0.966188  \n",
        "std       0.257586        0.338369         0.037184                  0.037156  \n",
        "min       0.181963        0.141499         0.901538                  0.892601  \n",
        "25%       0.664961        0.823164         1.000000                  0.943692  \n",
        "50%       0.743933        0.943260         1.000000                  0.976836  \n",
        "75%       0.857325        1.000000         1.000000                  0.998750  \n",
        "max       1.000000        1.000000         1.000000                  1.000000  "
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Results by Subset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "regional = { 2453107 }\n",
      "print \"region / pew knight sutdy / 245107 \"\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, regional ) )\n",
      "print_results_by_measurement_type( df )\n",
      "\n",
      "ap_english_us_top_25 = { 2453107 }\n",
      "print \"ap_english_us_top25 / 8875027 \"\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, regional ) )\n",
      "print_results_by_measurement_type( df )\n",
      "\n",
      "political_blogs = { 125 }\n",
      "print \"political blogs / 125\"\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, political_blogs ) )\n",
      "print_results_by_measurement_type( df )\n",
      "\n",
      "\n",
      "russian = { 7796878 }\n",
      "print 'russian'\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, russian ) )\n",
      "print_results_by_measurement_type( df )\n",
      "\n",
      "print 'brazil'\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, {8877968,  8877969, 8877973, 8877970 } ) )\n",
      "print_results_by_measurement_type( df )\n",
      "\n",
      "arabic = { 8878255 }\n",
      "print 'arabic'\n",
      "df = get_data_frame_from_comparision_objects( filter_by_media_tags_id( comps_downloads, arabic ) )\n",
      "print_results_by_measurement_type( df )\n",
      "                                             "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'downloads_id'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-38-7aed3800cc54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mregional\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[1;36m2453107\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"region / pew knight sutdy / 245107 \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_frame_from_comparision_objects\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfilter_by_media_tags_id\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcomps_downloads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregional\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint_results_by_measurement_type\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-27-a557b95ecdaf>\u001b[0m in \u001b[0;36mget_data_frame_from_comparision_objects\u001b[1;34m(comparison_objects)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnew_comps\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'downloads_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2371\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2372\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2373\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2565\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2566\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2567\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \"\"\"\n\u001b[1;32m-> 1181\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/index.so\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3354)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/index.so\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3289)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'downloads_id'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "region / pew knight sutdy / 245107 \n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.keys()\n",
      "cols = [ column for column in df.columns if column.startswith('f1recall_' ) and not column.endswith('_dedup')]\n",
      "\n",
      "df.sort( ['f1_python_readibilty'], ascending=[1] ).loc[:, cols ].head( 10 )\n",
      "#comps_downloads[ 0] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ cd for cd in comps_downloads if cd[ 'downloads_id' ] == 590441662  ]\n",
      "\n",
      "eto = [ extractor_training_object for extractor_training_object in extractor_training_objects  if extractor_training_object['downloads_id' ] == 590441662 ][0]\n",
      "\n",
      "print eto[ 'story']['url']\n",
      "print \"The problem is that this page has 2 articles on it. Readability zeros in on the second one instead of the first one\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eto = [ extractor_training_object for extractor_training_object in extractor_training_objects  if extractor_training_object['downloads_id' ] == 420599387][0]\n",
      "\n",
      "print eto[ 'story']['url']\n",
      "#print eto.keys()\n",
      "print eto['expected_lines']\n",
      "extract_with_python_readability( eto['raw_content'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}