{
 "metadata": {
  "name": "",
  "signature": "sha256:e6196607dd61c04b365dcdf3394745636fe47d3eacdb8cc3057303b0c60176d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mediacloud, requests, csv, sys, os, json, cPickle\n",
      "from pyroc import *\n",
      "\n",
      "#extractor_training_lines_checked has the training lines for downloads for which the highest line listed as 'included' was less than the number of lines in the download (max(included_line_numbers) < len(story_lines.json()))\n",
      "f = open(\"extractor_training_lines_checked.json\").read()\n",
      "reader = json.loads(f)\n",
      "heur = []\n",
      "cPickle.dump(heur, open(\"heur.p\", \"wb\"))\n",
      "crf = []\n",
      "cPickle.dump(crf, open(\"crf.p\", \"wb\"))\n",
      "done = []\n",
      "cPickle.dump(done, open(\"done.p\", \"wb\"))\n",
      "\n",
      "for row in reader:\n",
      "    \n",
      "    did = row[u'downloads_id']\n",
      "    lns = row[u'included_line_numbers']\n",
      "    \n",
      "    curh, curc = gen_data(did, lns)\n",
      "    \n",
      "    heur+=curh\n",
      "    crf+=curc\n",
      "    done.append(did)\n",
      "    \n",
      "    cPickle.dump(done, open(\"done.p\", \"wb\"))\n",
      "    cPickle.dump(heur, open(\"heur.p\", \"wb\"))\n",
      "    cPickle.dump(crf, open(\"crf.p\", \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "from pyroc import *\n",
      "\n",
      "heur = cPickle.load(open(\"heur.p\",\"rb\"))\n",
      "crf = cPickle.load(open(\"crf.p\",\"rb\"))\n",
      "\n",
      "rocheur = ROCData(heur)\n",
      "roccrf = ROCData(crf)\n",
      "\n",
      "print area(rocheur)\n",
      "\n",
      "plot_multiple_roc(rocList=(rocheur,roccrf), title='Extractor ROC Curve', labels=(\"heuristic curve\",\"crf curve\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_data(downloads_id, included_line_numbers):\n",
      "    \n",
      "    heuristic_training_ip = []\n",
      "    c_t_ip = []\n",
      "    \n",
      "    try:\n",
      "        \n",
      "        api_key = ''\n",
      "        loc_key = ''\n",
      "    \n",
      "        download = requests.get('https://api.mediacloud.org/api/v2/downloads/single/'+str(downloads_id)+'?key='+api_key)\n",
      "        raw_content = download.json()[0][u'raw_content']\n",
      "        stories_id = download.json()[0][u'stories_id']\n",
      "    \n",
      "        story = requests.get('https://api.mediacloud.org/api/v2/stories/single/'+str(stories_id)+'?key='+api_key)\n",
      "        title = story.json()[0][u'title']\n",
      "        description = story.json()[0][u'description']\n",
      "        url = story.json()[0][u'url']\n",
      "\n",
      "        story_lines_params = {'key':loc_key, 'body_html':raw_content}\n",
      "        story_lines = requests.get('http://0:3000/api/v2/extractlines/story_lines',params=story_lines_params)\n",
      "        preprocessed_lines = story_lines.text\n",
      "\n",
      "        heur_extract_params = {'key':loc_key, 'preprocessed_lines':preprocessed_lines, 'story_title':title, 'story_description':description, 'extractor_method':'HeuristicExtractor'}\n",
      "        heur_extract = requests.get('http://0:3000/api/v2/extractlines/extract',params=heur_extract_params)\n",
      "\n",
      "        crf_extract_params = {'key':loc_key, 'preprocessed_lines':preprocessed_lines, 'story_title':title, 'story_description':description, 'extractor_method':'CrfExtractor'}\n",
      "        crf_extract = requests.get('http://0:3000/api/v2/extractlines/extract',params=crf_extract_params)\n",
      "\n",
      "        for ln, hscore in enumerate(heur_extract.json()[u'scores']):\n",
      "\n",
      "            t = 1 if str(ln) in included_line_numbers else 0\n",
      "\n",
      "            if hscore[u'autoexcluded'] != 1:\n",
      "                h_t_ip.append( (t, hscore[u'include_probability']) )\n",
      "\n",
      "            cscore = crf_extract.json()[u'scores'][ln]\n",
      "            if u'autoexcluded' not in cscore:\n",
      "                c_t_ip.append( (t, cscore[u'include_probability']) ) \n",
      "    \n",
      "    except Exception as e:\n",
      "        \n",
      "        pass\n",
      "\n",
      "    return h_t_ip, c_t_ip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    }
   ],
   "metadata": {}
  }
 ]
}